#!/bin/sh
srun \
-K \
--container-mounts=/netscratch:/netscratch,/ds:/ds,$HOME:$HOME \
--container-workdir=/netscratch/angelova/experiments/sl-translation \
--container-image=/netscratch/avramidis/containers/lefterav+marian-nmt+1.10.0_sentencepiece_cuda-11.3.0_1.sqsh \
--ntasks=1 \
--nodes=1 \
--gpus=4 \
-p RTX6000 \
/marian/build/marian train \
--devices 0 1 2 3 \
--model /netscratch/angelova/experiments/sl-translation/model/model_nematus_unigram_1.npz \
--type s2s \
--dim-rnn 1024 \
--dim-emb 512 \
--enc-depth 1 \
--dec-depth 2 \
--enc-cell lstm \
--enc-cell-depth 2 \
--dec-cell-base-depth 2 \
--dec-cell lstm \
--layer-normalization \
--dropout-rnn 0.5 \
--dropout-src 0.4 \
--dropout-trg 0.4 \
--label-smoothing 0.2 \
--max-length 200 \
--mini-batch 32 \
--learn-rate 0.0005 \
--optimizer adam \
--early-stopping 10 \
--beam-size 5 \
--cost-type=ce-mean-words \
--valid-metrics ce-mean-words perplexity translation bleu-detok \
--dim-vocabs 2600 2600 \
--sentencepiece-options '--model_type=unigram --vocab_size=2600 --hard_vocab_limit=true' \
--train-sets /netscratch/angelova/data/sl-translation/glosses_train.txt /netscratch/angelova/data/sl-translation/sentences_train.txt \
--vocabs /netscratch/angelova/experiments/sl-translation/model/vocab.gl_nem_unigram_1.spm /netscratch/angelova/experiments/sl-translation/model/vocab.de_nem_unigram_1.spm \
--valid-sets /netscratch/angelova/experiments/sl-translation/glosses_dev.txt /netscratch/angelova/experiments/sl-translation/sentences_dev.txt \
--log /netscratch/angelova/experiments/sl-translation/model/valid_nem_unigram_1.log \
--lr-warmup 16000 \
--keep-best \
--valid-freq 500 \
--disp-freq 1000 \
--optimizer-params 0.9 0.98 1e-09 \
