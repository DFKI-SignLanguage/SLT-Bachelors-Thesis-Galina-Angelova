{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Script for extracting the german sentences</center> \n",
    "## <center>from the EAF transcripts A and B of the annotated DGS Corpus</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "from bs4 import BeautifulSoup \n",
    "import requests \n",
    "from urllib.parse import urljoin \n",
    "import urllib.request \n",
    "import pandas as pd \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of the DGS Corpus \n",
    "url_dgs_corpus = \"https://www.sign-lang.uni-hamburg.de/meinedgs/ling/start-name_en.html\" \n",
    "\n",
    "#request the dgs corpus page \n",
    "r = requests.get(url_dgs_corpus) \n",
    "\n",
    "#get the html contennt of the dgs corpus page \n",
    "html = r.text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a content soup from the html content of the dgs corpus page with BeautifulSoup\n",
    "content_soup = BeautifulSoup(html, 'html.parser') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rows with all types of files - ILEX, EAF, MP4...    \n",
    "rows_with_transcripts = content_soup.find('table', {'class': 'transcripts'}).find_all('tr') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list with all hrefs of the EAF files  \n",
    "list_eaf_files = []  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the cells with transcripts data \n",
    "for r in rows_with_transcripts[1:]: \n",
    "    cells_with_transcripts = r.find_all('td') \n",
    "    \n",
    "    #cells with the EAF transcript files \n",
    "    eaf_files = cells_with_transcripts[5] \n",
    "    \n",
    "    #add the href of each EAF transcript file to a list   \n",
    "    if(eaf_files.find('a')) != None:\n",
    "        list_eaf_files.append(eaf_files.find('a').attrs['href']) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list with the absolute urls of each EAF transcript \n",
    "absolute_paths_eaf_transcripts = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an absolute path for each EAF transcript with \n",
    "#taking the base url of the DGS Corpus and \n",
    "#the href of each EAF transcript from the list_eaf_files \n",
    "\n",
    "for single_eaf in list_eaf_files: \n",
    "    absolute_url = urljoin(url_dgs_corpus, single_eaf) \n",
    "    absolute_paths_eaf_transcripts.append(absolute_url)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.sign-lang.uni-hamburg.de/meinedgs/eaf/1413451-11105600-11163240.eaf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is how an element from the list looks like: \n",
    "absolute_paths_eaf_transcripts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1.5px solid gray\"></hr> \n",
    "\n",
    "#### Speakers A: \n",
    "\n",
    "  - *german sentences:* \n",
    "       - <b>TIER_ID=\"Deutsche_&#xDC;bersetzung_A\"</b> \n",
    "  - *german gloss sentences:* \n",
    "       - <b>TIER_ID=\"Lexem_Geb&#xE4;rde_r_A\" \n",
    "       - LINGUISTIC_TYPE_REF=\"L_tokens_right_left__finer_granularity\"</b> \n",
    "\n",
    "<hr style=\"border: 0.5px solid gray\"></hr>   \n",
    "\n",
    "#### Speakers B: \n",
    "  - *german sentences:* \n",
    "       - <b>TIER_ID=\"Deutsche_&#xDC;bersetzung_B\"</b> \n",
    "  - *german gloss sentences:*\n",
    "       - <b>TIER_ID=\"Lexem_Geb&#xE4;rde_r_B\" \n",
    "       - LINGUISTIC_TYPE_REF=\"L_tokens_right_left__finer_granularity\"</b>  \n",
    "\n",
    "<hr style=\"border:1.5px solid gray\"></hr> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Extract the german sentences from speakers A <center>     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a list with the content of all tags that have the attribute \"ANNOTATION_VALUE\" (they include german glosses, german sentences, \n",
    "#english glosses, english sentences, etc.) \n",
    "\n",
    "#from this content *only* the tags with german sentences from speakers A must be extracted  \n",
    "transcript_content_a = [] \n",
    "\n",
    "#this is a list for the specific time encoding of each sentence \n",
    "time_encodings_a = [] \n",
    "\n",
    "#this is a list of the german sentences \n",
    "german_sentences_a = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#take each transcript from the list with all EAF transcripts and read its content to extract \n",
    "#in a data frame all german sentences *only* for speakers A \n",
    "for transcript in absolute_paths_eaf_transcripts:    \n",
    "    with urllib.request.urlopen(transcript) as f:\n",
    "        content = f.read().decode('utf-8') \n",
    "        transcript_content_a = BeautifulSoup(content, 'xml').find_all(name=\"ANNOTATION_VALUE\") \n",
    "        time_encodings_a = BeautifulSoup(content, 'xml').find_all(name=\"TIME_SLOT\") \n",
    "        for value in range(0, len(transcript_content_a)): \n",
    "            #if the value of the tags attribute TIER_ID is a german sentence from speaker A, extract it \n",
    "            if transcript_content_a[value].parent.parent.parent.attrs['TIER_ID'] == \"Deutsche_Übersetzung_A\": \n",
    "                #this is the time encoding for the sentence (both starting and ending) \n",
    "                time = transcript_content_a[value].parent.attrs \n",
    "                #this is the starting time of the sentence \n",
    "                start = time['TIME_SLOT_REF1'] \n",
    "                #this is the ending time of the sentencec \n",
    "                end = time['TIME_SLOT_REF2'] \n",
    "                #the sentence itself \n",
    "                sentence_a = transcript_content_a[value].text \n",
    "                #group the sentence + its start + its end \n",
    "                sentence_group_a = [sentence_a, start, end] \n",
    "                #add the german sentence to the list of german sentences \n",
    "                german_sentences_a.append(sentence_group_a)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the list with german sentences A using pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the list using pickle where each element is: sentence A + start + end \n",
    "#to be used later without extracting it again  \n",
    "\n",
    "with open(\"path\", \"wb\") as fp: \n",
    "    pickle.dump(german_sentences_a, fp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a data frame for the sentences A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list with only the sentence (no timestamps included) \n",
    "data_a = [] \n",
    "\n",
    "for s in range(0, len(german_sentences_a)): \n",
    "    data_a.append(german_sentences_a[s][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>German Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wie mein Leben aussieht?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Na ja, ich bin als Gehörloser aufgewachsen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ich habe eher das Gefühl, wenn ich mir vorstel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Da treffe ich lieber viele Gehörlose und mache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aber das ist ja klar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31537</th>\n",
       "      <td>Nach der Pause.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31538</th>\n",
       "      <td>Wenn die Schule vorbei war, wie sah es dann au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31539</th>\n",
       "      <td>Aber es war auch möglich, dass du beispielswei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31540</th>\n",
       "      <td>Hast du dir das dann von einem Nachbarn geben ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31541</th>\n",
       "      <td>Ja, ja.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31542 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         German Sentence\n",
       "0                               Wie mein Leben aussieht?\n",
       "1            Na ja, ich bin als Gehörloser aufgewachsen.\n",
       "2      Ich habe eher das Gefühl, wenn ich mir vorstel...\n",
       "3      Da treffe ich lieber viele Gehörlose und mache...\n",
       "4                                  Aber das ist ja klar.\n",
       "...                                                  ...\n",
       "31537                                    Nach der Pause.\n",
       "31538  Wenn die Schule vorbei war, wie sah es dann au...\n",
       "31539  Aber es war auch möglich, dass du beispielswei...\n",
       "31540  Hast du dir das dann von einem Nachbarn geben ...\n",
       "31541                                            Ja, ja.\n",
       "\n",
       "[31542 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a data frame from the list \n",
    "df_a = pd.DataFrame(data_a, columns=[\"German Sentence\"])      \n",
    "\n",
    "df_a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save it as a file where each sentence is on a new line \n",
    "df_a.to_csv(f\"path\", encoding=\"utf-8-sig\", index=False, header=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1.5px solid gray\"></hr> \n",
    " \n",
    "### <center>Extract the german sentences from the transcripts B<center>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a list with the content of all tags that have the attribute \"ANNOTATION_VALUE\" (they include german glosses, german sentences, \n",
    "#english glosses, english sentences, etc.) \n",
    "\n",
    "#from this content *only* the tags with german sentences from speakers B must be extracted   \n",
    "transcript_content_b = [] \n",
    "\n",
    "#this is a list for the specific time encoding of each sentence \n",
    "time_encodings_b = [] \n",
    "\n",
    "#this is a list of the german sentences \n",
    "german_sentences_b = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#take each transcript from the list with all EAF transcripts and read its content to extract \n",
    "#in a data frame all german sentences *only* for speakers B    \n",
    "for transcript in absolute_paths_eaf_transcripts:    \n",
    "    with urllib.request.urlopen(transcript) as f:\n",
    "        content = f.read().decode('utf-8') \n",
    "        transcript_content_b = BeautifulSoup(content, 'xml').find_all(name=\"ANNOTATION_VALUE\") \n",
    "        time_encodings_b = BeautifulSoup(content, 'xml').find_all(name=\"TIME_SLOT\") \n",
    "        for value in range(0, len(transcript_content_b)): \n",
    "            #if the value of the tags attribute TIER_ID is a german sentence from speaker B, extract it  \n",
    "            if transcript_content_b[value].parent.parent.parent.attrs['TIER_ID'] == \"Deutsche_Übersetzung_B\": \n",
    "                #this is the time encoding for the sentence (both starting and ending) \n",
    "                time = transcript_content_b[value].parent.attrs \n",
    "                #this is the starting time of the sentence \n",
    "                start = time['TIME_SLOT_REF1'] \n",
    "                #this is the ending time of the sentencec \n",
    "                end = time['TIME_SLOT_REF2'] \n",
    "                #the sentence itself \n",
    "                sentence_b = transcript_content_b[value].text \n",
    "                #group the sentence + its start + its end \n",
    "                sentence_group_b = [sentence_b, start, end] \n",
    "                #add the german sentence to the list of german sentences \n",
    "                german_sentences_b.append(sentence_group_b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the list with german sentences B using pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the list using pickle where each element is: sentence + start + time \n",
    "#to use it for extracting the gloss sentences later \n",
    "\n",
    "with open(\"path\", \"wb\") as fp: \n",
    "    pickle.dump(german_sentences_b, fp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a data frame for the sentences B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list with only the sentence from the list with sentences B (no timestamps included) \n",
    "data_b = [] \n",
    "\n",
    "for s in range(0, len(german_sentences_b)): \n",
    "    data_b.append(german_sentences_b[s][0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>German Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich war traurig, als ich von Dianas tödlichem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denn als sie noch am Leben war, hat sie der We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sie war die beste und netteste Königin von Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Darum war ich schockiert und traurig über den ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weil es sie nicht mehr geben würde.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32375</th>\n",
       "      <td>Hausaufgaben? In Mathematik, Deutsch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32376</th>\n",
       "      <td>Wenn ich zum Beispiel im Unterricht nicht fert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32377</th>\n",
       "      <td>Wenn man die Aufgaben vergaß, gab es eine Strafe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32378</th>\n",
       "      <td>Wenn der fertig war?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32379</th>\n",
       "      <td>Dann hat er sie mir gegeben, selbstverständlich.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32380 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         German Sentence\n",
       "0      Ich war traurig, als ich von Dianas tödlichem ...\n",
       "1      Denn als sie noch am Leben war, hat sie der We...\n",
       "2      Sie war die beste und netteste Königin von Eng...\n",
       "3      Darum war ich schockiert und traurig über den ...\n",
       "4                    Weil es sie nicht mehr geben würde.\n",
       "...                                                  ...\n",
       "32375              Hausaufgaben? In Mathematik, Deutsch.\n",
       "32376  Wenn ich zum Beispiel im Unterricht nicht fert...\n",
       "32377  Wenn man die Aufgaben vergaß, gab es eine Strafe.\n",
       "32378                               Wenn der fertig war?\n",
       "32379   Dann hat er sie mir gegeben, selbstverständlich.\n",
       "\n",
       "[32380 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a data frame from the list with sentences B \n",
    "df_b = pd.DataFrame(data_b, columns=[\"German Sentence\"])       \n",
    "\n",
    "df_b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save it as a file where each sentence is on a new line \n",
    "df_b.to_csv(f\"path\", encoding=\"utf-8-sig\", index=False, header=False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1.5px solid gray\"></hr> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating df_a and df_b gives a total of 63922 sentences  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_a, df_b] \n",
    "\n",
    "result = pd.concat(frames) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data frame with the concatenated data frames for sentences a and sentences b \n",
    "result.to_csv(f\"path\", encoding=\"utf-8-sig\", index=False, header=False)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
